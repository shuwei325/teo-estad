<!DOCTYPE html>
<html lang="es"><head>
<script src="Clase_15_files/libs/clipboard/clipboard.min.js"></script>
<script src="Clase_15_files/libs/quarto-html/tabby.min.js"></script>
<script src="Clase_15_files/libs/quarto-html/popper.min.js"></script>
<script src="Clase_15_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="Clase_15_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Clase_15_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="Clase_15_files/libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.25">

  <meta name="author" content="Shu Wei Chou Chen">
  <title>Contraste de hipótesis4</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="Clase_15_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="Clase_15_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="Clase_15_files/libs/revealjs/dist/theme/quarto-829c66079de1ba6dba869a367cd4b667.css">
  <link href="Clase_15_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="Clase_15_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="Clase_15_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="Clase_15_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Contraste de hipótesis<sup>4</sup></h1>
  <p class="subtitle"><a href="https://swchouchen.github.io/teo-estad">Curso: Teoría Estadística</a></p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
<a href="https://shuwei325.github.io">Shu Wei Chou Chen</a> <a href="https://orcid.org/0000-0001-5495-2486" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
</div>
<div class="quarto-title-author-email">
<a href="mailto:shuwei.chou@ucr.ac.cr">shuwei.chou@ucr.ac.cr</a>
</div>
        <p class="quarto-title-affiliation">
            <a href="https://www.estadistica.ucr.ac.cr/">
            Escuela de Estadística, Universidad de Costa Rica
            </a>
          </p>
    </div>
</div>

</section>
<section id="qué-vamos-a-discutir-hoy" class="slide level2">
<h2>¿Qué vamos a discutir hoy?</h2>
<ul>
<li>Hemos visto hasta ahora sobre
<ul>
<li>Todo sobre estimadores puntuales + pivotes e intervalos de confianza.</li>
<li>Contrastes de hipótesis (función de potencia, tamaño del contraste, el valor p, contrastes más potentes, uniformemente más potentes).</li>
</ul></li>
<li>Ahora:
<ul>
<li>Contrastes de hipótesis: constrastes más potentes y uniformemente más potentes. Cocientes de verosimilitud.</li>
</ul></li>
</ul>
<div class="cell">
<style type="text/css">
code {
  font-size: 2em;
  /* or try font-size: xx-large; */
}
</style>
</div>
</section>
<section id="contraste-de-razón-de-verosimilitudes" class="slide level2">
<h2>Contraste de razón de verosimilitudes</h2>
<p>En la parte anterior encontramos un método para encontrar la región crítica de un contraste cuando se contrastan dos hipótesis simples (o hipótesis compuestas generalizables) sin embargo, el Lema de Neyman-Pearson no es capaz de encontrar una región crítica cuando las hipótesis son compuestas y no se pueden generalizar a manera de encontrar un contraste UMP.</p>
<p>Una manera de hacer esto es por medio del contraste de razón de verosimilitudes que nos da una forma más general de trabajar con las propiedades de verosimilitud y aún así obtener un buen contraste a partir de él.</p>
</section>
<section class="slide level2">

<p><strong>Definición 4.10:</strong> <em>Estadístico de la razón de verosimilitudes</em>. Suponga que se tiene una muestra aleatoria <span class="math inline">\(X_{1}, X_{2}, ... , X_{n}\)</span> de una población con vector de parámetros <span class="math inline">\(\Theta = (\theta_1, \theta_2, ... , \theta_k)\)</span> y con función de verosimilitud <span class="math inline">\(\mathcal{L}(\Theta)\)</span>. Se desea hacer un contraste de hipótesis sobre uno o más de estos parámetros, de forma que las hipótesis sean compuestas, es decir podemos tener hipótesis <span class="math inline">\(H_{0}: \Theta \in \Omega_{0}\)</span> contra <span class="math inline">\(H_{1}: \Theta \in \Omega_{1}\)</span>. Entonces se definen <span class="math inline">\(\mathcal{L}(\hat{\Omega}_{0}) = \max\limits_{\Theta \in \Omega_{0}}\mathcal{L}(\Theta)\)</span> y <span class="math inline">\(\mathcal{L}(\hat{\Omega}) = \max\limits_{\Theta \in \Omega}\mathcal{L}(\Theta)\)</span>. Estos corresponden a las funciones de verosimilitud evaluadas en sus correspondientes máximos de verosimilitud. Se define el <span class="alert">estadístico de la razón de verosimilitudes</span>, denotado <span class="math inline">\(\lambda\)</span>, como <span class="math inline">\(\frac{\mathcal{L}(\hat{\Omega}_{0})}{\mathcal{L}(\hat{\Omega})}\)</span>.</p>
<p>De esta definición podemos inferir el uso que se le puede dar a dicho estadístico. Se puede demostrar que <span class="math inline">\(0 &lt; \lambda &lt; 1\)</span>. Si <span class="math inline">\(\lambda\)</span> es un valor muy cercano a uno esto significa que la mejor explicación de la verosimilitud está siendo dada por los valores de <span class="math inline">\(\Omega_{0}\)</span>, mientras que pasa lo contrario si <span class="math inline">\(\lambda\)</span> se aproxima mucho a cero. Por lo tanto, un buen contraste consistiría en rechazar <span class="math inline">\(H_0\)</span> si <span class="math inline">\(\lambda &lt; k\)</span>, donde el <span class="math inline">\(k\)</span> se elije como anteriormente, fijando el tamaño.</p>
</section>
<section class="slide level2">

<p>Empezaremos mostrando la técnica con un ejemplo sencillo que consiste de solo un parámetro desconocido. Bajo este esquema podemos definir el estadístico <span class="math inline">\(\lambda\)</span> como <span class="math inline">\(\lambda = \frac{\mathcal{L}(\theta_0)}{\mathcal{L}(\hat{\theta})}\)</span>, donde <span class="math inline">\(\theta_0\)</span> es el valor especificado en la hipótesis nula y <span class="math inline">\(\hat{\theta}\)</span> es el EMV de <span class="math inline">\(\theta\)</span>.</p>
<p><strong>Ejemplo:</strong> Sea <span class="math inline">\(X_{1}, X_{2}, ... , X_{n}\)</span> una muestra aleatoria tal que <span class="math inline">\(X_{j} \sim N(\mu,\sigma^2)\)</span> donde <span class="math inline">\(\mu\)</span> es desconocido y <span class="math inline">\(\sigma^2\)</span> es conocido. Se desean contrastar las siguientes hipótesis:</p>
<p><span class="math display">\[H_{0}: \mu = \mu_0 \text{ contra } H_{1}: \mu \neq \mu_0\]</span></p>
<p>Obtenga un contraste con un nivel de significancia de <span class="math inline">\(\alpha_0\)</span>.</p>
</section>
<section class="slide level2">

<p><strong>Solución:</strong> Lo primero que se puede notar es que la hipótesis alterna es compuesta y no existe un contraste UMP para todo <span class="math inline">\(\mu \neq \mu_0\)</span>, por lo que no podemos usar el Lema de Neyman-Pearson y deberemos usar la razón de verosimilitudes. Sabemos de antemano que <span class="math inline">\(\mathcal{L}(\mu) = (2\pi)^{-\frac{n}{2}} (\sigma^2)^{-\frac{n}{2}} e^{-\frac{\sum(x_{j} -\mu)^2}{2\sigma^2}}\)</span> Por lo tanto:</p>
<p><span class="math inline">\(\mathcal{L}(\hat{\Omega}_0) = \mathcal{L}(\mu_0) = (2\pi)^{-\frac{n}{2}} (\sigma^2)^{-\frac{n}{2}} e^{-\frac{\sum(X_{j} -\mu_0)^2}{2\sigma^2}} = (2\pi)^{-\frac{n}{2}} (\sigma^2)^{-\frac{n}{2}} e^{-\frac{ \sum{X_{j}^{2}} - 2n\mu_{0} \bar{X} + n\mu_{0}^2 }{2\sigma^2}}\)</span></p>
<p>También sabemos, de temas anteriores del curso, que el estimador de máxima verosimilitud para <span class="math inline">\(\mu\)</span> es <span class="math inline">\(\hat{\mu} = \bar{X}\)</span>. Evaluando esto en la verosimilitud de todo <span class="math inline">\(\Omega\)</span> obtenemos:</p>
<p><span class="math inline">\(\mathcal{L}(\hat{\Omega}) = \mathcal{L}(\hat{\mu}) =  \mathcal{L}(\bar{X}) = (2\pi)^{-\frac{n}{2}} (\sigma^2)^{-\frac{n}{2}} e^{-\frac{ \sum{X_{j}^{2}} - 2n\bar{X} \cdot \bar{X} + n\bar{X}^2 }{2\sigma^2}} = (2\pi)^{-\frac{n}{2}} (\sigma^2)^{-\frac{n}{2}} e^{-\frac{ \sum{X_{j}^{2}} - n\bar{X}^2 }{2\sigma^2}}\)</span></p>
</section>
<section class="slide level2">

<p>De esta manera tenemos:</p>
<p><span class="math inline">\(\lambda = \frac{\mathcal{L}(\mu_0)}{\mathcal{L}(\hat{\mu})} = \frac{(2\pi)^{-\frac{n}{2}} (\sigma^2)^{-\frac{n}{2}} e^{-\frac{ \sum{X_{j}^{2}} - 2n\mu_{0} \bar{X} + n\mu_{0}^2 }{2\sigma^2}}}{(2\pi)^{-\frac{n}{2}} (\sigma^2)^{-\frac{n}{2}} e^{-\frac{ \sum{X_{j}^{2}} - n\bar{X}^2 }{2\sigma^2}}} = e^{\frac{-n\left( \bar{X} - \mu_0\right) ^2}{2\sigma^2}}\)</span></p>
<p>Sabemos que el contraste consiste en rechazar <span class="math inline">\(H_0\)</span> si <span class="math inline">\(\lambda &lt; k\)</span>, es decir</p>
<p><span class="math inline">\(e^{\frac{-n\left( \bar{X} - \mu_0\right) ^2}{2\sigma^2}} &lt; k\)</span></p>
<p><span class="math inline">\(\Rightarrow \frac{-n\left( \bar{X} - \mu_0\right) ^2}{2\sigma^2} &lt; \ln(k)\)</span></p>
<p><span class="math inline">\(\Rightarrow \frac{n\left( \bar{X} - \mu_0\right) ^2}{\sigma^2} &gt; -2\ln(k) = k^{\prime}\)</span></p>
</section>
<section class="slide level2">

<p>Nótese que cuando <span class="math inline">\(H_0\)</span> es cierto entonces <span class="math inline">\(\frac{n\left( \bar{X} - \mu_0\right) ^2}{\sigma^2} \sim \chi^{2}_{(1)}\)</span>. Por lo tanto el valor de <span class="math inline">\(k^{\prime}\)</span> es el valor de la tabla de la chi-cuadrada con un grado de libertad que acumula una probabilidad de <span class="math inline">\(\alpha_0\)</span> a su derecha, es decir <span class="math inline">\(k^{\prime} = \chi^{2}_{1-\alpha_0,1}\)</span>. Por lo tanto el contraste consiste en rechazar la hipótesis nula cuando <span class="math inline">\(\frac{n\left( \bar{X} - \mu_0\right) ^2}{\sigma^2} &gt; \chi^{2}_{1-\alpha_0,1}\)</span>.</p>
<p>Observe que esta regla de decisión puede expresarse por medio de otra distribución. Sacando la raíz cuadrada a ambos lados, tenemos:</p>
<p><span class="math display">\[\left| \frac{\sqrt{n}\left( \bar{X} - \mu_0\right)}{\sigma}\right| &gt; \sqrt{k^{\prime}}=c.\]</span></p>
<p>El lado izquierdo de la inecuación va a ser positiva si <span class="math inline">\(\bar{X} &gt; \mu_0\)</span> o negativa si <span class="math inline">\(\bar{X} &lt; \mu_0\)</span>. Dada la hipótesis alternativa, nosotros sabemos que <span class="math inline">\(\bar{X}\)</span> es tanto menor como mayor a <span class="math inline">\(\mu_0\)</span>, por lo que podríamos decir que rechazamos <span class="math inline">\(H_0\)</span> si <span class="math inline">\(\frac{\sqrt{n}\left( \bar{X} - \mu_0\right)}{\sigma} &gt; c\)</span> o <span class="math inline">\(\frac{\sqrt{n}\left( \bar{X} - \mu_0\right)}{\sigma} &lt; -c\)</span>.</p>
</section>
<section class="slide level2">

<p>Si <span class="math inline">\(H_0\)</span> es cierta entonces <span class="math inline">\(\frac{\sqrt{n}\left( \bar{X} - \mu_0\right)}{\sigma} \sim N(0,1)\)</span>. Si queremos encontrar el valor de <span class="math inline">\(c\)</span> lo podemos despejar igual que anteriormente, por medio del tamaño fijo:</p>
<p><span class="math inline">\(\alpha_0 = P\left( \frac{\sqrt{n}\left( \bar{X} - \mu_0\right)}{\sigma} &gt; c  \right) +  P\left( \frac{\sqrt{n}\left( \bar{X} - \mu_0\right)}{\sigma} &lt; -c  \right)\)</span></p>
<p>Como el valor que estamos intentando encontrar es el mismo en valor absoluto eso significa que: <span class="math inline">\(P\left( \frac{\sqrt{n}\left( \bar{X} - \mu_0\right)}{\sigma} &gt; c  \right) = P\left( \frac{\sqrt{n}\left( \bar{X} - \mu_0\right)}{\sigma} &lt; -c  \right) = \frac{\alpha_0}{2}\)</span></p>
<p>Esto quiere decir que <span class="math inline">\(c = z_{1-\frac{\alpha_0}{2}}\)</span>. Entonces el contraste anterior es equivalente a rechazar <span class="math inline">\(H_0\)</span> si <span class="math inline">\(\frac{\sqrt{n}\left( \bar{X} - \mu_0\right)}{\sigma} &gt; z_{1-\frac{\alpha_0}{2}}\)</span> o <span class="math inline">\(\frac{\sqrt{n}\left( \bar{X} - \mu_0\right)}{\sigma} &lt; -z_{1-\frac{\alpha_0}{2}}\)</span> por lo que podemos ver que esta es la prueba que normalmente se utiliza en la práctica.</p>
</section>
<section class="slide level2">

<p>Ahora procedamos a generalizar este ejemplo:</p>
<p><strong>Ejemplo:</strong> Sea <span class="math inline">\(X_{1}, X_{2}, ... , X_{n}\)</span> una muestra aleatoria tal que <span class="math inline">\(X_{j} \sim N(\mu,\sigma^2)\)</span> donde <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma^2\)</span> son desconocidos. Se desean contrastar las siguientes hipótesis:</p>
<p><span class="math display">\[H_{0}: \mu = \mu_0 \text{ contra } H_{1}: \mu \neq \mu_0\]</span></p>
<p>Obtenga un contraste con un nivel de significancia de <span class="math inline">\(\alpha_0\)</span>.</p>
<p><strong>Solución:</strong> A diferencia del caso pasado, ahora ambas hipótesis son compuestas. En este caso tenemos que <span class="math inline">\(\Theta = (\mu, \sigma^2)\)</span>, a diferencia del caso anterior en donde solo teníamos un parámetro desconocido. Por lo tanto vamos a requerir los EMV de cada parámetro:</p>
<p><span class="math inline">\(\hat{\mu} = \bar{X}\)</span></p>
<p><span class="math inline">\(\hat{\sigma}^2 =\frac{\sum(x_{j} -\bar{X})^2}{n}\)</span></p>
</section>
<section class="slide level2">

<p>Sin embargo, si definimos <span class="math inline">\(\Theta_{0}\)</span> como el vector de parámetros definidos por <span class="math inline">\(H_0\)</span> tendríamos que <span class="math inline">\(\Theta_0 = (\mu_0 , \sigma^2)\)</span>. Por lo tanto, la verosimilitud definida para <span class="math inline">\(\Theta_{0}\)</span> es:</p>
<p><span class="math inline">\(\mathcal{L}(\Theta_0) = (2\pi)^{-\frac{n}{2}} (\sigma^2)^{-\frac{n}{2}} e^{-\frac{\sum(X_{j} -\mu_0)^2}{2\sigma^2}}\)</span></p>
<p>Nótese que <span class="math inline">\(\sigma^2\)</span> sigue siendo desconocido, por lo que vamos a tener que estimarlo. Resulta que su estimador máximo verosimil viene dado por <span class="math inline">\(\hat{\sigma}^{2}_{0} = \frac{\sum(x_{j} -\mu_0)^2}{n}\)</span>. Ahora procedamos a obtener las funciones de verosimilitud evaluadas en sus respectivos máximos verosímiles:</p>
<p><span class="math inline">\(\mathcal{L}(\hat{\Omega}_0) = (2\pi)^{-\frac{n}{2}} (\hat{\sigma}^{2}_{0})^{-\frac{n}{2}} e^{-\frac{\sum(x_{j} -\mu_0)^2}{2\hat{\sigma}^{2}_{0}}} = (2\pi)^{-\frac{n}{2}} \left( \frac{\sum(x_{j} -\mu_0)^2}{n}\right) ^{-\frac{n}{2}} e^{-\frac{n\sum(x_{j} -\mu_0)^2}{2\sum(x_{j} -\mu_0)^2}}\)</span></p>
<p><span class="math inline">\(= (2\pi)^{-\frac{n}{2}} \left( \frac{\sum(x_{j} -\mu_0)^2}{n}\right) ^{-\frac{n}{2}} e^{-\frac{n}{2}}\)</span></p>
<p><span class="math inline">\(\mathcal{L}(\hat{\Omega}) = (2\pi)^{-\frac{n}{2}} (\hat{\sigma}^2)^{-\frac{n}{2}} e^{-\frac{\sum(x_{j} -\bar{X})^2}{2\hat{\sigma}^2}} = (2\pi)^{-\frac{n}{2}} \left( \frac{\sum(x_{j} -\bar{X})^2}{n}\right) ^{-\frac{n}{2}} e^{-\frac{n\sum(x_{j} -\bar{X})^2}{2\sum(x_{j} -\bar{X})^2}}= (2\pi)^{-\frac{n}{2}} \left( \frac{\sum(x_{j} -\bar{X} )^2}{n}\right) ^{-\frac{n}{2}} e^{-\frac{n}{2}}\)</span></p>
</section>
<section class="slide level2">

<p>Por lo tanto, el estadístico de la razón de verosimilitudes sería:</p>
<p><span class="math inline">\(\lambda = \frac{(2\pi)^{-\frac{n}{2}} \left( \frac{\sum(x_{j} -\mu_0)^2}{n}\right) ^{-\frac{n}{2}} e^{-\frac{n}{2}}}{(2\pi)^{-\frac{n}{2}} \left( \frac{\sum(x_{j} -\bar{X} )^2}{n}\right) ^{-\frac{n}{2}} e^{-\frac{n}{2}}} = \left( \frac{\sum(x_{j} -\bar{X} )^2}{\sum(x_{j} -\mu_0)^2} \right)^{\frac{n}{2}} &lt; k\)</span></p>
<p>Por lo tanto podemos decir que rechazamos la hipótesis nula si <span class="math inline">\(\left( \frac{\sum(x_{j} -\bar{X} )^2}{\sum(x_{j} -\mu_0)^2} \right)^{\frac{n}{2}} &lt; k\)</span>. No obstante, podemos hacer ciertos desarrollos matemáticos a esta desigualdad para llegar a un estadístico con distribución conocida.</p>
<p><span class="math inline">\(\left( \frac{\sum(x_{j} -\bar{X} )^2}{\sum(x_{j} -\mu_0)^2} \right)^{\frac{n}{2}} &lt; k\)</span> <span class="math inline">\(\Rightarrow  \left( \frac{\sum(x_{j} -\bar{X} )^2}{\sum(x_{j} -\bar{X})^2 + n(\bar{X} - \mu_0)^2} \right)^{\frac{n}{2}} &lt; k\)</span> <span class="math inline">\(\Rightarrow  \frac{\sum(x_{j} -\bar{X} )^2}{\sum(x_{j} -\bar{X})^2 + n(\bar{X} - \mu_0)^2}  &lt; k^{\frac{2}{n}}\)</span> <span class="math inline">\(\Rightarrow  \frac{1}{  \frac{\sum(x_{j} -\bar{X})^2 + n(\bar{X} - \mu_0)^2}{\sum(x_{j} -\bar{X} )^2}   } &lt; k^{\frac{2}{n}}\)</span> <span class="math inline">\(\Rightarrow  \frac{1}{ 1 + \frac{n(\bar{X} - \mu_0)^2}{\sum(x_{j} -\bar{X} )^2}   } &lt; k^{\frac{2}{n}}\)</span> <span class="math inline">\(\Rightarrow  \frac{n(\bar{X} - \mu_0)^2}{\sum(x_{j} -\bar{X} )^2} &gt;   k^{-\frac{2}{n}} - 1\)</span> <span class="math inline">\(\Rightarrow  \frac{n(\bar{X} - \mu_0)^2}{ \frac{1}{n-1} \sum(x_{j} -\bar{X} )^2} &gt;  (n-1) \left( k^{-\frac{2}{n}} - 1\right)\)</span> <span class="math inline">\(\Rightarrow  \frac{n(\bar{X} - \mu_0)^2}{ S^2} &gt;  (n-1) \left( k^{-\frac{2}{n}} - 1\right) = k^{\prime}\)</span></p>
</section>
<section class="slide level2">

<p>De esta forma llegamos a una distribución conocida. Hemos demostrado en el curso anterior que <span class="math inline">\(\frac{n(\bar{X} - \mu_0)^2}{ S^2} \sim F_{(1,n-1)}\)</span>. Por lo tanto, utilizando el nivel de significancia <span class="math inline">\(\alpha_0\)</span> obtenemos que <span class="math inline">\(k^{\prime} = F_{1-\alpha_0,1,n-1}\)</span>. Es decir, rechazamos la hipótesis nula si <span class="math inline">\(\frac{n(\bar{X} - \mu_0)^2}{S^2} &gt; F_{1-\alpha_0,1,n-1}\)</span>. Si sacamos la raíz cuadrada del contraste anterior obtenemos que vamos a rechazar <span class="math inline">\(H_0\)</span> si <span class="math inline">\(\frac{\sqrt{n}(\bar{X} - \mu_0)}{S} &gt; c\)</span> o si <span class="math inline">\(\frac{\sqrt{n}(\bar{X} - \mu_0)}{S} &lt; -c\)</span> donde <span class="math inline">\(c = \sqrt{F_{1-\alpha_0,1,n-1}}\)</span>. No obstante podemos reconocer la distribución de <span class="math inline">\(\frac{\sqrt{n}(\bar{X} - \mu_0)}{S}\)</span> la cual es una t-Student con <span class="math inline">\(n-1\)</span> grados de libertad. Por lo tanto, equivale decir que <span class="math inline">\(c=t_{1-\alpha_0/2,n-1}\)</span>. Esta región crítica corresponde la prueba T utilizada en la práctica para este problema.</p>
<p>El método de la razón de verosimilitudes tiene un inconveniente y es que en muchas ocasiones es imposible generar un estadístico con distribución conocida a partir de <span class="math inline">\(\lambda\)</span>. Sin embargo, podemos hacer uso del Teorema de Wilks que veremos a continuación.</p>
</section>
<section class="slide level2">

<p><strong>Teorema 4.3:</strong> <em>Teorema de Wilks</em>. Suponga que <span class="math inline">\(X_{1}, X_{2}, ... , X_{n}\)</span> tiene una función de verosimilitud <span class="math inline">\(\mathcal{L}(\Theta)\)</span> con <span class="math inline">\(\Theta\)</span> el vector de parámetros, y se tienen las hipótesis <span class="math inline">\(H_{0}: \Theta \in \Omega_0\)</span> contra <span class="math inline">\(H_{1}: \Theta \in \Omega_1\)</span>. Sean <span class="math inline">\(d = \dim(\Omega)\)</span> y <span class="math inline">\(d_0 = \dim(\Omega_0)\)</span>. Si <span class="math inline">\(n \to \infty\)</span> entonces <span class="math display">\[G=-2\ln(\lambda)  \xrightarrow{\text{d}} \chi^{2}_{(d-d_0)}.\]</span></p>
<ul>
<li>El resultado de este teorema es inmediato pues podemos ver que para cualquier contraste de tamaño <span class="math inline">\(\alpha_0\)</span>, si <span class="math inline">\(n\)</span> es suficientemente grande, podemos construir un contraste que consiste en rechazar la hipótesis nula si <span class="math inline">\(G=-2\ln(\lambda) &gt; \chi^{2}_{1-\alpha_0,d-d_{0}}\)</span>.</li>
<li>De esta forma tenemos una región crítica genérica que dependerá del tamaño del contraste y de <span class="math inline">\(d\)</span> y <span class="math inline">\(d_0\)</span>.</li>
</ul>
</section>
<section class="slide level2">

<p><strong>Ejemplo:</strong> Sea <span class="math inline">\(X_{1}, X_{2}, ... , X_{n}\)</span> una muestra aleatoria tal que <span class="math inline">\(X_{j} \sim Exp(\theta)\)</span> y suponga que se desean contrastar las hipótesis <span class="math inline">\(H_{0}: \theta = \theta_0\)</span> contra <span class="math inline">\(H_{1}: \theta \neq \theta_0\)</span>. Encuentre el contraste de razón de verosimilitudes para un tamaño de <span class="math inline">\(\alpha_0\)</span>.</p>
<p><strong>Solución:</strong> Empecemos definiendo <span class="math inline">\(\Omega\)</span> y <span class="math inline">\(\Omega_0\)</span>. Tenemos un único parámetro de interés <span class="math inline">\(\Theta=\theta\)</span> y que <span class="math inline">\(\Omega = \left\lbrace \theta \in \mathbb{R^+} \right\rbrace\)</span> y que <span class="math inline">\(\Omega_{0} = \left\lbrace \theta_0 \right\rbrace\)</span>. Por lo tanto <span class="math inline">\(\dim(\Omega) = 1\)</span> y <span class="math inline">\(\dim(\Omega_0) = 0\)</span>. Sigamos obteniendo la verosimilitud para este problema:</p>
<p><span class="math inline">\(\mathcal{L}(\Theta) = \mathcal{L}(\theta) = \theta^{-n} e^{-\frac{\sum x_j}{\theta}} =  \theta^{-n} e^{-\frac{n \bar{x}}{\theta}}\)</span></p>
<p>De este resultado podemos demostrar fácilmente que el EMV de <span class="math inline">\(\theta\)</span> es <span class="math inline">\(\bar{X}\)</span>. Por lo tanto tenemos las siguientes verosimilitudes evaluadas en sus máximos verosímiles:</p>
<p><span class="math inline">\(\mathcal{L}(\theta_0) = \theta_{0}^{-n} e^{-\frac{n \bar{x}}{\theta_0}}\)</span>, y</p>
<p><span class="math inline">\(\mathcal{L}(\hat{\theta}) = \mathcal{L}(\bar{X}) = \bar{X}^{-n} e^{-n}\)</span></p>
</section>
<section class="slide level2">

<p>Por lo tanto tenemos que el estadístico de la razón de verosimilitudes es</p>
<p><span class="math inline">\(\lambda = \frac{\mathcal{L}(\theta_0)}{\mathcal{L}(\hat{\theta})} = \frac{\theta_{0}^{-n} e^{-\frac{n \bar{x}}{\theta_0}}}{\bar{X}^{-n} e^{-n}} = \left( \frac{\bar{X}}{\theta_0}  \right)^{n} e^{-n\left( \frac{\bar{X}}{\theta_0} - 1 \right) }\)</span></p>
<p>Si aplicamos el teorema de Wilks tenemos la siguiente estadística:</p>
<p><span class="math inline">\(G = -2\ln(\lambda) = -2n\left[  \ln(\bar{X}) - \ln(\theta_0) + 1 - \frac{\bar{X}}{\theta_0} \right]\)</span></p>
<p>Por lo tanto, vamos a rechazar la hipótesis nula si <span class="math inline">\(G &gt; \chi^{2}_{1-\alpha_0,1}\)</span>.</p>
</section>
<section class="slide level2">

<p>Sin embargo, para este contraste podemos encontrar una región crítica exacta, sin necesidad de aplicar el Teorema de Wilks. Sea <span class="math inline">\(T = \frac{n\bar{X}}{\theta_0}\)</span>, de forma que</p>
<p><span class="math inline">\(\lambda = g(T) = n^{-n} T^{n} e^{-(T-n)}\)</span></p>
<p>Recuerde que el contraste de la razón de verosimilitudes consiste en rechazar la hipótesis nula si <span class="math inline">\(\lambda &lt; k\)</span> es decir, si <span class="math inline">\(g(T) &lt; k\)</span>.</p>
</section>
<section class="slide level2">

<div class="columns">
<div class="column" style="width:50%;">
<p>En la figura podemos observar la gráfica de <span class="math inline">\(g(T)\)</span> para <span class="math inline">\(T &gt;0\)</span>. La línea punteada en el gráfico corresponde al valor teórico de <span class="math inline">\(k\)</span>. Nótese que <span class="math inline">\(g(T) &lt; k\)</span> si <span class="math inline">\(T &lt; k_1\)</span> o si <span class="math inline">\(T &gt; k_2\)</span>, donde <span class="math inline">\(k_1\)</span> y <span class="math inline">\(k_2\)</span> se eligen utilizando el tamaño del contraste. Por lo tanto, vamos a rechazar la hipótesis nula si <span class="math inline">\(T &lt; k_1\)</span> o <span class="math inline">\(T &gt; k_2\)</span>.</p>
</div><div class="column" style="width:50%;">
<p>Suponiendo <span class="math inline">\(n=7\)</span>, <span class="math inline">\(\alpha_0 = 0.05\)</span> y <span class="math inline">\(\theta_{0} = 1\)</span>, el gráfico de <span class="math inline">\(g(T)\)</span>:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="Clase_15_files/figure-revealjs/unnamed-chunk-3-1.png" width="480"></p>
</figure>
</div>
</div>
</div>
</div></div>
</section>
<section class="slide level2">

<ul>
<li>Para obtener los valores <span class="math inline">\(k_1\)</span> y <span class="math inline">\(k_2\)</span> los despejamos de la siguiente ecuación:</li>
</ul>
<p><span class="math display">\[P\left( T &lt; k_1 | \theta_0 \right) = P\left( T &gt; k_2 | \theta_0 \right) = \frac{\alpha_0 }{2}\]</span></p>
<ul>
<li>Sabemos que bajo <span class="math inline">\(H_0\)</span> cierto <span class="math inline">\(T \sim Gamma(n,1)\)</span>, por lo tanto <span class="math inline">\(W = 2T \sim \chi^{2}_{(2n)}\)</span>. Por lo tanto la ecuación anterior equivale a</li>
</ul>
<p><span class="math display">\[P\left( W &lt; k_{1}^{\prime} | \theta_0 \right) = P\left( W &gt; k_{2}^{\prime} | \theta_0 \right) = \frac{\alpha_0}{2}\]</span></p>
<ul>
<li>Por lo tanto <span class="math inline">\(k_{1}^{\prime} = \chi^{2}_{\frac{\alpha_0 }{2},2n}\)</span> y <span class="math inline">\(k_{2}^{\prime} = \chi^{2}_{1-\frac{\alpha_0}{2},2n}\)</span>. Es decir, vamos a rechazar la hipótesis nula si <span class="math inline">\(\frac{2n\bar{X}}{\theta_0} &lt; \chi^{2}_{\frac{\alpha_0 }{2},2n}\)</span> o si <span class="math inline">\(\frac{2n\bar{X}}{\theta_0} &gt; \chi^{2}_{1-\frac{\alpha_0 }{2},2n}\)</span>.</li>
</ul>
</section>
<section class="slide level2">

<p>En la siguiente Figura podemos ver una comparación de la potencia exacta y aproximada para este ejemplo, utilizando <span class="math inline">\(n=7\)</span>, <span class="math inline">\(\alpha_0 = 0.05\)</span> y <span class="math inline">\(\theta_{0} = 1\)</span>. Nótese como la prueba aproximada tiene una perdida en potencia para <span class="math inline">\(\theta &gt; 1\)</span>.</p>

<img data-src="Clase_15_files/figure-revealjs/unnamed-chunk-4-1.png" width="480" class="r-stretch quarto-figure-center"><p class="caption">Comparación de potencias</p></section>
<section class="slide level2">

<p><strong>Ejemplo:</strong> Sean <span class="math inline">\(X_{1}, X_{2}, ... , X_{n}\)</span> y <span class="math inline">\(Y_{1}, Y_{2}, ... , Y_{n}\)</span> dos muestras aleatorias independientes tales que <span class="math inline">\(X_{j} \sim \operatorname{Poisson}(\theta_1)\)</span> y <span class="math inline">\(Y_{j} \sim \operatorname{Poisson}(\theta_2)\)</span>. Se desea contrastar las hipótesis <span class="math inline">\(H_{0}: \theta_1 = \theta_2\)</span> contra <span class="math inline">\(H_{1}: \theta_1 \neq \theta_2\)</span>. Encuentre un contraste para estas hipótesis utilizando el Teorema de Wilks.</p>
<p><strong>Solución:</strong> Tenemos que <span class="math inline">\(\Theta=(\theta_1,\theta_2)\)</span>. En el caso de <span class="math inline">\(\Omega_{0}\)</span> tenemos que este se define como <span class="math inline">\(\Omega_{0} = \left\lbrace (\theta_1 , \theta_2) | \theta_1 = \theta_2 = \theta&gt;0 \right\rbrace\)</span>. Por otra parte, <span class="math inline">\(\Omega = \left\lbrace (\theta_1 , \theta_2) | \theta_1 , \theta_2 \in \mathbb{R}^{+}  \right\rbrace\)</span>. Por lo tanto tenemos que <span class="math inline">\(\Omega_{0}  = \left\lbrace \theta| \theta \in \mathbb{R}^+ \right\rbrace\)</span> y <span class="math inline">\(\Theta =\left\lbrace (\theta_1 , \theta_2) \in \mathbb{R}^+ \times \mathbb{R}^+  \right\rbrace\)</span> y sus dimensiones son 1 y 2, respectivamente. Procedamos a encontrar la verosimilitud:</p>
<p><span class="math inline">\(\mathcal{L}(\Theta) = \mathcal{L}(\theta_1 , \theta_2) = \mathcal{L}(\theta_1) \mathcal{L}(\theta_2) = \frac{\theta_{1}^{\sum X_{j}} e^{-n\theta_{1}}}{\prod X_{j}!} \frac{\theta_{2}^{\sum Y_{j}} e^{-n\theta_{2}}}{\prod Y_{j}!} = \frac{\left( \theta_{1}^{\bar{X}} \theta_{2}^{\bar{Y}}  \right)^{n} e^{-n(\theta_{1}+\theta_{2})} }{\prod X_{j}! \prod Y_{j}!}\)</span></p>
</section>
<section class="slide level2">

<p>Se puede demostrar que de esta expresión se obtiene <span class="math inline">\(\bar{X}\)</span> como EMV de <span class="math inline">\(\theta_1\)</span> y <span class="math inline">\(\bar{Y}\)</span> como EMV de <span class="math inline">\(\theta_2\)</span>. Ahora procedamos a encontrar la verosimilitud evaluada en <span class="math inline">\(\Theta_{0}\)</span>:</p>
<p><span class="math inline">\(\mathcal{L}(\Theta_0) = \mathcal{L}(\theta) = \frac{\theta^{ n(\bar{X} + \bar{Y}) } e^{-2n\theta} }{\prod X_{j}! \prod Y_{j}!}\)</span></p>
<p>Ahora debemos encontrar el EMV de <span class="math inline">\(\theta\)</span>. Para ello sacamos primero la log-verosimilitud:</p>
<p><span class="math inline">\(\ell(\theta) = n(\bar{X} + \bar{Y})\ln(\theta) - 2n\theta - \ln\left( \prod X_{j}! \prod Y_{j}! \right)\)</span></p>
<p><span class="math inline">\(\Rightarrow \frac{\partial \ell (\theta)}{\partial \theta} = \frac{ n(\bar{X} + \bar{Y}) }{\theta} - 2n = 0\)</span></p>
<p><span class="math inline">\(\Rightarrow \hat{\theta} = \frac{\bar{X} + \bar{Y}}{2}\)</span></p>
<p>La segunda derivada con respecto a <span class="math inline">\(\theta\)</span> sería negativa, por lo que <span class="math inline">\(\hat{\theta}\)</span> es el EMV.</p>
</section>
<section class="slide level2">

<p>Ahora procedemos a encontrar <span class="math inline">\(\mathcal{L}(\hat{\Omega})\)</span> y <span class="math inline">\(\mathcal{L}(\hat{\Omega}_0)\)</span>.</p>
<p><span class="math inline">\(\mathcal{L}(\hat{\Omega}_0) = \frac{ \left( \frac{\bar{X} + \bar{Y}}{2} \right) ^{ n(\bar{X} + \bar{Y}) } e^{-n(\bar{X} + \bar{Y})} }{\prod X_{j}! \prod Y_{j}!}\)</span></p>
<p><span class="math inline">\(\mathcal{L}(\hat{\Omega}) = \frac{\left( \bar{X}^{\bar{X}} \bar{Y}^{\bar{Y}}  \right)^{n} e^{-n(\bar{X}+\bar{Y})} }{\prod X_{j}! \prod Y_{j}!}\)</span></p>
<p>Por lo tanto, el estadístico <span class="math inline">\(\lambda\)</span> sería:</p>
<p><span class="math inline">\(\lambda = \frac{\mathcal{L}(\hat{\Omega}_0)}{\mathcal{L}(\hat{\Omega})} = \left( \frac{\left( \frac{\bar{X} + \bar{Y}}{2} \right) ^{ (\bar{X} + \bar{Y}) }}{\bar{X}^{\bar{X}} \bar{Y}^{\bar{Y}}} \right)^{n}\)</span></p>
</section>
<section class="slide level2">

<p>Ya con esto podemos encontrar una expresión para la estadística <span class="math inline">\(G\)</span>:</p>
<p><span class="math inline">\(G = -2\ln(\lambda) = -2\ln \left( \frac{\left( \frac{\bar{X} + \bar{Y}}{2} \right) ^{ (\bar{X} + \bar{Y}) }}{\bar{X}^{\bar{X}} \bar{Y}^{\bar{Y}}} \right)^{n}\)</span></p>
<p><span class="math inline">\(= -2n\left[ (\bar{X} + \bar{Y}) \ln\left( \frac{\bar{X} + \bar{Y}}{2}\right)  - \bar{X} \ln(\bar{X}) - \bar{Y} \ln(\bar{Y}) \right]\)</span></p>
<p>Por el Teorema de Wilks, rechazamos la hipótesis nula si este valor es mayor a <span class="math inline">\(\chi^{2}_{1-\alpha_0,1}\)</span>.</p>
</section>
<section class="slide level2">

<p>Como parte adicional del ejemplo, supongamos que <span class="math inline">\(n=100\)</span>, <span class="math inline">\(\bar{x} = 20\)</span>, <span class="math inline">\(\bar{y} = 22\)</span> y <span class="math inline">\(\alpha_0 = 0.01\)</span>. Utilicemos estos valores para contrastar las hipótesis del ejemplo. Con estos valores se tiene que <span class="math inline">\(G \approx 9.53\)</span> y que <span class="math inline">\(\chi^{2}_{0.99,1} = 6.635\)</span>. Tenemos que <span class="math inline">\(G &gt; \chi^{2}_{0.99,1}=6.635\)</span> por lo que rechazamos la hipótesis nula.</p>
</section>
<section id="contraste-de-wald" class="slide level2">
<h2>Contraste de Wald</h2>
<p>En el tema pasado, presentamos la distribución asintótica de los estimadores de máxima verosimilitud. Recordemos que bajo las condiciones del teorema, tenemos que para el EMV <span class="math inline">\(\hat{\theta}\)</span> de <span class="math inline">\(\theta\)</span>, tenemos</p>
<p><span class="math display">\[\left[I(\theta)\right]^{1/2}(\hat{\theta}_n - \theta) \stackrel{d}{\longrightarrow} N(0,1),\]</span> donde <span class="math inline">\(I(\theta)\)</span> es la información de Fisher. De esta forma, tenemos que</p>
<p><span class="math display">\[\left[I(\theta)\right](\hat{\theta}_n - \theta)^2 \stackrel{d}{\longrightarrow} \chi_{(1)}^2.\]</span> Como consecuencia, tenemos la definición del estadístico de Wald.</p>
</section>
<section class="slide level2">

<p><strong>Definición 4.11:</strong> <em>Estadístico de Wald</em>. Sea <span class="math inline">\(X_1,...,X_n\)</span> una muestra aleatoria de una población con distribución que depende de <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\hat{\theta}_n\)</span> es el EMV de <span class="math inline">\(\theta\)</span>. Se desea contrastar las hipótesis: <span class="math display">\[H_{0}: \theta = \theta_0,~~~~ \text{contra}~~~~ H_{1}: \theta \neq \theta_0.\]</span> El <span class="alert">estadístico de Wald</span> se define como <span class="math display">\[W= (\hat{\theta}_n - \theta_0)I(\hat{\theta})(\hat{\theta}_n - \theta_0).\]</span></p>
<p><strong>Teorema 4.4:</strong> <em>Contraste de Wald</em> Bajo las mismas condiciones , el <span class="alert">contraste de Wald</span> con un nivel de significancia <span class="math inline">\(\alpha_0\)</span>, consiste en rechazar <span class="math inline">\(H_0\)</span>, si <span class="math display">\[W&gt;\chi^2_{(1-\alpha_0,1)}.\]</span></p>
</section>
<section class="slide level2">

<p><strong>Ejemplo:</strong> Recordemos en el ejemplo anterior, en donde nos interesa contrastar las hipótesis <span class="math inline">\(H_{0}: \theta = \theta_0\)</span> contra <span class="math inline">\(H_{1}: \theta \neq \theta_0\)</span>. Encuentre el contraste de razón de verosimilitudes para un tamaño de <span class="math inline">\(\alpha_0\)</span>.</p>
<p><strong>Solución:</strong> Se puede comprobar que <span class="math inline">\(\hat{\theta}=\bar{X}\)</span>, <span class="math inline">\(I(\beta)=\frac{n}{\beta^2}\)</span>. Suponga que <span class="math inline">\(\theta_0=1\)</span> y con <span class="math inline">\(n=7\)</span> se obtiene <span class="math inline">\(\bar{X}=5\)</span>. Por lo tanto, <span class="math display">\[W=(\hat{\theta}_n - \theta_0)I(\hat{\theta})(\hat{\theta}_n - \theta_0)=\left(\frac{7}{5^2}\right)(5-1)^2=4.48.\]</span> Con <span class="math inline">\(\alpha_0=0.05\)</span>, <span class="math inline">\(W=4.48&gt;\chi^2_{(1-\alpha_0,1)}=3.8415\)</span>. Es decir, el contraste de Wald sugiere rechazar la hipótesis nula con un nivel de significancia de <span class="math inline">\(0.05\)</span>.</p>
</section>
<section class="slide level2">

<p>Por otro lado, si utilizamos el contraste de razón de verosimilitud, tenemos que <span class="math display">\[V=\frac{2n\bar{X}}{\theta_0}=\frac{2\cdot7\cdot 5}{1}=70&gt;\chi^2_{0.975,2\cdot7}=26.11.\]</span> Finalmente, por el teorema de Wilks, <span class="math display">\[G = -2\ln(\lambda) = -2n\left[  \ln(\bar{X}) - \ln(\theta_0) + 1 - \frac{\bar{X}}{\theta_0} \right]\]</span> <span class="math display">\[=-2\cdot 7 \left( \ln(3.5) - \ln(1) +1 - \frac{3.5}{1} \right)=33.47.\]</span> Como <span class="math inline">\(G=33.467&gt;\chi^2_{(1-\alpha_0,1)}=3.8415\)</span>, el teorema de Wilks sugiere rechazar la hipótesis nula con nivel de significancia de <span class="math inline">\(0.05\)</span>.</p>
</section>
<section id="lab04b" class="slide level2">
<h2>Lab04b</h2>
<p><a href="lab04b.html">Lab04b</a></p>
</section>
<section id="qué-discutimos-hoy" class="slide level2">
<h2>¿Qué discutimos hoy?</h2>
<ul>
<li>Contrastes de razón de verosimilitud.</li>
<li>Teorema de Wilks.</li>
<li>Estadístico de Wald.</li>
</ul>
</section>
<section id="ejercicio" class="slide level2">
<h2>Ejercicio:</h2>

<img data-src="figs/ejercicio_hipotesis.png" class="r-stretch"></section>
<section class="slide level2">

<ol type="1">
<li>Suponga que <span class="math inline">\(Y_1, Y_2, \ldots, Y_n\)</span> denotan una muestra aleatoria de la distribución de Poisson con media <span class="math inline">\(\lambda\)</span>.</li>
</ol>
<ol type="a">
<li>Encuentre el estimador de máxima verosimilitud <span class="math inline">\(\hat{\lambda}\)</span> para <span class="math inline">\(\lambda\)</span>.</li>
<li>Suponga que se desea contrastar las hipótesis <span class="math inline">\(H_0: \lambda=\lambda_0\)</span> contra <span class="math inline">\(H_0: \lambda \neq \lambda_0\)</span>. Encuentre el estadístico de Wald y establezca la región crítica del contraste de Wald con <span class="math inline">\(\alpha=0.05\)</span>.</li>
<li>Simule en R una muestra aleatoria de tamaño <span class="math inline">\(10\)</span> con distribución Poisson de <span class="math inline">\(\lambda=15\)</span>. Luego contrasta las hipótesis <span class="math inline">\(H_0: \lambda=10\)</span> contra <span class="math inline">\(H_0: \lambda \neq 10\)</span>, usando el contraste encontrado en b.</li>
<li>Repita el ejercicio c, pero con la muestra simulada con <span class="math inline">\(\lambda=11\)</span>.</li>
</ol>
</section>
<section class="slide level2">

<ol start="2" type="1">
<li>Suponga que <span class="math inline">\(Y_1, Y_2, \ldots, Y_n\)</span> denotan una muestra aleatoria de una población distribuida exponencialmente con media <span class="math inline">\(\theta\)</span>.</li>
</ol>
<ol type="a">
<li>Encuentre el estimador de máxima verosimilitud de la variacia poblacional <span class="math inline">\(\theta^2\)</span>.</li>
<li>Suponga que se desea contrastar las hipótesis <span class="math inline">\(H_0: \theta^2=4\)</span> contra <span class="math inline">\(H_0: \theta^2 \neq 4\)</span>. Encuentre el estadístico de Wald y establezca la región crítica del contraste de Wald con <span class="math inline">\(\alpha=0.01\)</span>.</li>
<li>Simule en R una muestra aleatoria de tamaño <span class="math inline">\(15\)</span> con distribución exponencial de <span class="math inline">\(\theta=1\)</span>. Luego contrasta las hipótesis <span class="math inline">\(H_0: \theta^2=4\)</span> contra <span class="math inline">\(H_0: \theta^2 \neq 4\)</span>, usando el contraste encontrado en b.</li>
<li>Repita el ejercicio c, pero con una muestra simulada de tamaño <span class="math inline">\(5\)</span>.</li>
</ol>

</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="Clase_15_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="Clase_15_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="Clase_15_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="Clase_15_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="Clase_15_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="Clase_15_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="Clase_15_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="Clase_15_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="Clase_15_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="Clase_15_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"right","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true,"width":"wide","numbers":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    

    <script>

      // htmlwidgets need to know to resize themselves when slides are shown/hidden.

      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current

      // slide changes (different for each slide format).

      (function () {

        // dispatch for htmlwidgets

        function fireSlideEnter() {

          const event = window.document.createEvent("Event");

          event.initEvent("slideenter", true, true);

          window.document.dispatchEvent(event);

        }

    

        function fireSlideChanged(previousSlide, currentSlide) {

          fireSlideEnter();

    

          // dispatch for shiny

          if (window.jQuery) {

            if (previousSlide) {

              window.jQuery(previousSlide).trigger("hidden");

            }

            if (currentSlide) {

              window.jQuery(currentSlide).trigger("shown");

            }

          }

        }

    

        // hookup for slidy

        if (window.w3c_slidy) {

          window.w3c_slidy.add_observer(function (slide_num) {

            // slide_num starts at position 1

            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);

          });

        }

    

      })();

    </script>

    

    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copiado");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copiado");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>